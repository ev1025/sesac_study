{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4466ed30-3d01-497c-bc9e-33e28b77381f",
   "metadata": {},
   "source": [
    "### OpenAI에서 지원하는 GPT API 사용 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e94e5de-00d4-41d5-b8a9-0ecbeddca3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.61.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.5.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp38-cp38-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.27.2-cp38-cp38-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\envy\\anaconda3\\envs\\study\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.61.0-py3-none-any.whl (460 kB)\n",
      "Downloading anyio-4.5.2-py3-none-any.whl (89 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.8.2-cp38-cp38-win_amd64.whl (194 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, jiter, httpcore, distro, anyio, annotated-types, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.5.2 distro-1.9.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.61.0 pydantic-2.10.6 pydantic-core-2.27.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4d0a2af-6fe3-4516-beef-b053dddf37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from getpass import getpass # 보안 정보를 화면에 표시 없이 입력받을 때 사용하는 모듈(api key 감추기용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86a9e0-d478-4eaf-8556-cb8348408d3a",
   "metadata": {},
   "source": [
    "### API KEY 설정\n",
    "- API key는 보안상 겉으로 보이지 않는 것이 좋으므로 감춰서 사용하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec88887c-8bb7-4337-9849-b63aa9db4698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "# 개인의 API key를 입력\n",
    "MY_API_KEY = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23ca7958-e91c-45dd-8a3f-bb650fbe595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 객체 생성\n",
    "client = OpenAI(api_key = MY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ea3ee-a815-44f3-948d-fd71b5920005",
   "metadata": {},
   "source": [
    "### GPT 모델 불러와서 일반적인 질의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43652b9c-1ecd-47ed-9405-210b60258109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt에게 입력할 텍스트\n",
    "question = \"안녕? 오늘 피크닉가기 좋은 날씨네!\"\n",
    "response = client.chat.completions.create(model = 'gpt-3.5-turbo',\n",
    "                                          messages = [{'role' : 'user', 'content':question}], # role은 user, system, assistant로 나뉨, system은 대전제\n",
    "                                          max_tokens = 150,\n",
    "                                          temperature = 0 # 0~2 낮을수록 간결하게(0.7이 디폴트)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5ba67-705b-43e5-bff0-2df414330441",
   "metadata": {},
   "source": [
    "### ChatCompletion 객체에는 사용자의 요청과 모델의 응답에 대한 정보가 담겨져 있음\n",
    "- content에 실제 텍스트 응답이 있으며, role에는 역할, model에는 사용된 모델명, usage에는 토큰 사용량에 대한 정보가 담겨져있음\n",
    "- 모델이 응답할 때 role은 항상 assistant로 출력됨(우리가 질의할 때는 user로 질의해야 함)\n",
    "- usage에 `prompt_tokens`는 입력 토큰(질의) 수, `completion_tokens`는 출력 토큰(응답)의 수가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b3e4558-8cef-4363-8de9-3afd991bc189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Awk6kGCr87DcTeRVBNR7nbIjlynUB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='네, 맞아요! 피크닉 가기 딱 좋은 날이네요. 햇살도 따뜻하고 바람도 시원해서 즐거운 시간 보내시길 바래요. 좋은 하루 되세요!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738563626, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=74, prompt_tokens=34, total_tokens=108, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c46ecbd-56a0-48fc-b9db-2b1b2fb36b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bb076fa-7141-4527-8da6-735135b48c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 맞아요! 피크닉 가기 딱 좋은 날이네요. 햇살도 따뜻하고 바람도 시원해서 즐거운 시간 보내시길 바래요. 좋은 하루 되세요!'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb4e4d-9628-4151-937b-e909f5396a6a",
   "metadata": {},
   "source": [
    "### 자주 발생되는 에러\n",
    "- RateLimitError : API 크레딧 금액 한도 초과\n",
    "- Invalid RequetError : 잘못된 요청\n",
    "- APIConnectionError : API 서버와의 연결 문제로 발생\n",
    "- OpenAIError : 일반적인 openai 라이브러리 사용시 발생되는 에러"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b43707-e4da-4882-9336-b746965ab2b4",
   "metadata": {},
   "source": [
    "### 프로그래밍 기술적인 내용 질의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb25a3-00f7-4639-bc40-6ff053c06c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt에게 입력할 텍스트\n",
    "question = \"Pandas DataFrame에서 중복 항목을 제거하는 방법은?\"\n",
    "response = client.chat.completions.create(model = 'gpt-3.5-turbo',\n",
    "                                          messages = [{'role' : 'user', 'content':question}],\n",
    "                                          max_tokens = 150,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f15974c-abdb-4853-bdf3-d810abe707f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas DataFrame에서 중복 항목을 제거하기 위해서는 `drop_duplicates()` 메소드를 사용하면 됩니다. 이 메소드는 중복된 행을 제거하여 유일한 값만을 남기고 새로운 DataFrame을 반환합니다. \n",
      "\n",
      "예를 들어, 다음과 같이 DataFrame에서 중복 항목을 제거할 수 있습니다.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# 샘플 데이터프레임 생성\n",
      "data = {'A': [1, 2, 2, 3, 4],\n",
      "        'B': ['x', 'y', 'y', '\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14321445-fd04-4f1d-bed3-42a80a5cef55",
   "metadata": {},
   "source": [
    "### 입력한 파일에 대한 분석 요청\n",
    "- 파일과 질의를 구분해서 사용자 정의 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad4a09d7-e272-47ba-b1ab-e2541419f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anlysis_data(data, question, model):\n",
    "    prompt = f\"Data: {data}\\nQuestion : {question}\"\n",
    "    response = client.chat.completions.create(model = model,\n",
    "                                              messages = [{'role':'user','content':prompt}],\n",
    "                                              max_tokens = 500\n",
    "                                             )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8613dbc-59f9-46b2-b486-18504cbd9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 데이터에서는 다음과 같이 BMI 범주별 데이터 개수가 나타납니다:\n",
      "\n",
      "- 저체중: 76명\n",
      "- 정상: 183명\n",
      "- 과체중: 134명\n",
      "- 비만: 107명\n",
      "- 고도비만: 0명\n"
     ]
    }
   ],
   "source": [
    "data = \"data/bmi_500.csv\"\n",
    "question = \"해당 데이터는 500명의 bmi점수야. 저체중부터 고도비만까지 데이터의 개수를 파악해서 출력해줘.\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "result = anlysis_data(data, question, model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe206198-c300-467d-b8e3-2acf75647f3a",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- API를 활용하여 로컬 PC에서 결과를 출력하려 한다면 사용자별로 환경이 다르기 때문에 시각화 요청에 대해 누구나 활용할 수 있는 형태로 제공됨\n",
    "- ChatGPT 웹 서비스에서는 3.5-turbo 버전에서 파일 입력이 불가하지만, 3.5-turbo API를 호출하여 사용하는 경우 로컬 PC 파일을 입력할 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:study]",
   "language": "python",
   "name": "conda-env-study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
