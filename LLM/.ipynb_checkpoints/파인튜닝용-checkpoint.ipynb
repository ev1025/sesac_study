{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f598a0f-e663-4d5a-b793-2697c4c71fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4eacc-4d21-4152-bc88-f5480ce59e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import tiktoken # openai 모델들이 사용하는 base 토큰화 + 인코딩 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fef4f-4852-4574-8f73-18e17956df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_API_KEY = getpass.getpass(\"OpenAI API Key :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47198b3c-37d4-4a21-afc2-78c7ab4c014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=MY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4cb5d-08f2-4465-85a0-d4263e665c30",
   "metadata": {},
   "source": [
    "## 데이터 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52fd5f-5f68-47ac-a413-74b030018b7a",
   "metadata": {},
   "source": [
    "### 1) Fine-tuning API의 규격에 맞는 데이터셋인지 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51254907-8b7b-41df-bf05-7446e266b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 존재하지 않는 key값이 들어오면 0을 기본값으로 함\n",
    "format_errors = defaultdict(int) \n",
    "\n",
    "for ex in dataset: # ex는 하나의 대화(messages)로 dict형태\n",
    "\n",
    "# 1) 대화데이터 형태 확인(dict)\n",
    "    if not isinstance(ex, dict):          # isinstance(객체명, 클래스명)으로 객체의 타입을 확인하여  True or False 반환\n",
    "        format_errors[\"data_type\"] += 1   # format_errors에는 {\"data_type\" : 0}인 상태가 디폴트로 생성\n",
    "        continue                          # ex가 dict가 아니면, not(False) -> True 반환하여 +1\n",
    "\n",
    "# 2) 대화데이터 존재 여부 확인\n",
    "    messages = ex.get('messages', None) # messages의 value값이 있는지 없는지 판단\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] +=1\n",
    "        continue\n",
    "\n",
    "# 3) 대화데이터 형식에 맞는 key값인지 확인\n",
    "    for message in messages: # 채팅 API가 아닌 경우, role, content 외에 다른 key값이 있을 수 있음\n",
    "        if any(key not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for key in message): # any = 하나라도 True라면\n",
    "            format_errors[\"message_unrecognized_key\"] +=1      \n",
    "\n",
    "        # message에 role과 content가 있는지 확인\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors['message_missing_key'] += 1\n",
    "\n",
    "        #  role이 system, user, assistant 중 하나가 아니라면\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        # content에 값이 없거나 문자열이 아니라면\n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1 \n",
    "\n",
    "    # 각 대화에 assistant의 응답이 하나도 없다면\n",
    "    # message들 중 하나라도 assistant의 응답이 있으면 any문은 전체를 T로 인식함\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_erros[\"example_missing_assistant_message\"] +=1\n",
    "\n",
    "# 발생한 에러가 있다면 해당 내용 출력\n",
    "if format_errors:\n",
    "    print(\"에러 발견:\")\n",
    "    for key, value in format_errors.items():\n",
    "        print(f\"{key}:{value}\")\n",
    "else:\n",
    "    print(\"에러가 없습니다.\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5f7c5-7195-4248-8c48-7396e8d6395e",
   "metadata": {},
   "source": [
    "### 2) 누락된 메세지 식별 및 메세지와 토큰 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12740a1d-2afe-4d9a-9a21-04e54eaca5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # get_encoding : 특정 토크나이저 인코딩 모델 검색\n",
    "                                                # cl100k_base : OpenAI 최신 LLM에 사용되는 모델명\n",
    "\n",
    "# 메세지 목록의 총 토큰 수 계산\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "\n",
    "    # tokens_per_message : \"role\" + \"content\" + \"{}\"를 토큰 3개로 임의 지정 (한 요소당 1로 대략 계산)\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message \n",
    "\n",
    "        # role과 content의 value를 tiktoken로 토큰화(encoding)하여 value의 토큰 개수 저장 \n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "\n",
    "            # key에 \"name\"이 존재하면 토큰 1개 추가 (사용자가 assistant의 이름을 지정할 경우 발생)\n",
    "            if key == \"name\": \n",
    "                num_tokens += tokens_per_name\n",
    "\n",
    "    # num_tokens += 3 하는 이유\n",
    "     # 1) 하나의 messages에 전체를 감싸는 토큰 : \"{}\"\n",
    "     # 2) 한 message의 끝을 표시하는 특수 토큰 (모델 내부에서 동작 <SEP> 등)\n",
    "     # 3) 각각의 message를 구분해주는 구분 토큰 : ','\n",
    "    num_tokens += 3 \n",
    "\n",
    "    return num_tokens\n",
    "\n",
    "# assistant가 응답한 content의 총 토큰 수 (모델의 max_output_tokens 기준에 맞는지 판단 가능)\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"])) # assistant의 content 토큰 수\n",
    "    return num_tokens\n",
    "\n",
    "# message의 토큰 길이에 대한 통계 정보 출력\n",
    "def print_statistics(values):\n",
    "    print(f\"min / max : {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median : {np.mean(values)}, {np.median(values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806bdaa-a1cf-4d12-a065-52d2a146a58d",
   "metadata": {},
   "source": [
    "#### [모델별 토큰 수 ](https://platform.openai.com/docs/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788a4a5-6499-41a1-8239-77249e0d7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_output_tokens = 16384    # 모델 최대 출력 토큰 수(gpt-4o-mini의 경우 16384개)\n",
    "n_missing_system = 0         # system이 없는 경우 대화 수\n",
    "n_missing_user = 0           # user가 없는 경우의 대화 수\n",
    "n_messages = []              # 각 대화의 message개수\n",
    "total_tokens_lens = []       # 각 대화의 총 토큰 수\n",
    "assistant_message_lens = []  # assistant가 보낸 메시지의 길이\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "\n",
    "    # system이 포함되어 있지 않으면 +1\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "\n",
    "    # user가 포함되어 있지 않으면 +1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "\n",
    "    # 각 대화별 메세지 개수\n",
    "    n_messages.append(len(messages))\n",
    "\n",
    "    # 각 대화별 총 토큰 개수(role도 다 포함)\n",
    "    total_tokens_lens.append(num_tokens_from_messages(messages))\n",
    "\n",
    "    # assistant's output 토큰 수\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"System 누락 수 : \", n_missing_system)\n",
    "print(\"User 누락 수 : \", n_missing_user)\n",
    "\n",
    "print()\n",
    "print(\"대화별 메시지 수 통계 : \")\n",
    "print_statistics(n_messages)\n",
    "\n",
    "print()\n",
    "print(\"대화별 토큰 수 통계 : \")\n",
    "print_statistics(total_tokens_lens)\n",
    "\n",
    "print()\n",
    "print(\"대화별 assistant 출력 토큰 수 통계 : \")\n",
    "print_statistics(assistant_message_lens)\n",
    "\n",
    "# total_tokens_lens(각 대화별 토큰 수 리스트)에서 최대값(16384)을 넘는 대화 수\n",
    "n_too_long = sum(i > max_output_tokens for i in total_tokens_lens)\n",
    "\n",
    "print()\n",
    "print(f\"\\n{n_too_long}개의 대화가 {max_output_tokens}개 토큰 제한을 초과하며 이 부분은 학습중 잘릴 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72edf5-2ddb-4b97-8e1b-d6e713a5ab8b",
   "metadata": {},
   "source": [
    "### 3) 적정 epochs 및 비용 추정\n",
    "- [파인튜닝 토큰 수](https://platform.openai.com/docs/guides/fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a3c44-c30b-4bb1-946f-0276af6215be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 맞는 대화당 최대 토큰 수 설정 (4o-mini의 Traning examples context length 기준)\n",
    "MAX_TOKENS_PER_EXAMPLE = 65536\n",
    "\n",
    "# OpenAI의 테스트에 의해 얻어진 적정 기준 (절대적인 기준은 아님!!!!!)\n",
    "TARGET_EPOCHS = 3             # 초기 학습 횟수 (GPT는 보통 처음에 2~4회로 지정)\n",
    "MIN_DEFAULT_EPOCHS = 1        # 최소 epochs\n",
    "MAX_DEFAULT_EPOCHS = 25       # 최대 epochs\n",
    "MIN_TARGET_EXAMPLES = 100     # fine-tuning 효과를 보기 위한 최소 데이터 수\n",
    "MAX_TARGET_EXAMPLES = 25000   # 최대 데이터 개수 (비용 및 시간 효율을 위해 상한 설정)\n",
    "\n",
    "\n",
    "# --------------- epoch 수 산정하기 ---------------\n",
    "n_epochs = TARGET_EPOCHS         # 초기 학습 횟수\n",
    "n_train_examples = len(dataset)  # messages의 개수\n",
    "\n",
    "# 대화 수(messages) * 초기 학습 횟수(epochs)가 최소 데이터 수에 못 미치면\n",
    "if (n_train_examples * TARGET_EPOCHS) < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, (MIN_TARGET_EXAMPLES//n_train_examples))  \n",
    "    \n",
    "# 대화 수(messages) * 초기 학습 횟수(epochs)가 최대 데이터 수를 넘기면\n",
    "elif (n_train_examples * TARGET_EPOCHS) > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, (MAX_TARGET_EXAMPLES//n_train_examples))\n",
    "# -----------------------------------------------\n",
    "\n",
    "\n",
    "# 대화별 토큰 수 (total_tokens_lens)와 MAX_TOKENS_PER_EXAMPLE 중 더 작은 토큰 수 더하기\n",
    "# MAX_TOKENS_PER_EXAMPLE(65536토큰)를 초과하면 어차피 나머지는 글은 잘리기 때문에\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in total_tokens_lens)\n",
    "\n",
    "\n",
    "print(f\"데이터 셋에는 학습 중 요금이 청구될 {n_billing_tokens_in_dataset}개의 토큰이 있습니다.\")\n",
    "print(f\"기본적으로 이 데이터 셋에서 {n_epochs} epochs 동안 학습합니다.\")\n",
    "print(f\"총 {n_epochs*n_billing_tokens_in_dataset}개의 토큰에 대해 요금이 청구됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ac86f-b862-43c9-9e61-a17afae1b5b5",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d67db-343d-40c9-8b3b-55a47fe17617",
   "metadata": {},
   "source": [
    "### 1) OpenAI Storage에 파일 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686190d-3e16-4c0d-bf33-e20d4e223e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_files = client.files.create(\n",
    "    file = open(\"finetune_data/common_sense_train.jsonl\", \"rb\"),  # rb를 하면 encoding이 필요 없음\n",
    "    purpose = \"fine-tune\"\n",
    ")\n",
    "fine_tune_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f110b17-986f-4d43-bff2-1bb0cef90512",
   "metadata": {},
   "source": [
    "### 작업 객체 생성 및 Fine-tuning 시작 ([모델명 참조](https://platform.openai.com/docs/guides/fine-tuning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9037332-bc7f-45f3-bd76-de3be62bd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 모델과 데이터 지정\n",
    "fine_tune_job = client.fine_tuning.jobs.create(\n",
    "    model = \"gpt-4o-mini-2024-07-18\",     # docs - Fine-tuning에 있는 모델 사용\n",
    "    training_file = fine_tune_files.id    # openai storage에 있는 파일의 id값을 지정\n",
    ")\n",
    "\n",
    "fine_tune_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd931d3-132a-4957-b393-13d93db5f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 작업 번호\n",
    "# ftjob-Ft82dD32EH1jaOumUtXOFHEv 이런식\n",
    "job_id = fine_tune_job.id \n",
    "\n",
    "# fine_tuned_model : 파인튜닝이 완료된 후 생성된 개인 모델 명칭 확인\n",
    "# ft:gpt-4o-mini-2024-07-18:personal::B1pKdhoJ 이런식\n",
    "model_id = client.fine_tuning.jobs.retrieve(job_id).fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5893a0-10b0-4b40-bde6-cdb3d0fa9e52",
   "metadata": {},
   "source": [
    "##### **status(선택)**\n",
    "- running(동작중), validating_files(파일 검증), queued(대기)\n",
    "- succeded(성공), fialed(실패), concelled(취소됨)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f3659-131e-4d8b-9c6b-9191016be0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.retrieve(job_id).status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd062d-ad00-406a-9685-528f6b627134",
   "metadata": {},
   "source": [
    "##### **작업로그, 성능 업데이트 또는 오류 메세지 같이 미세 조정 작업 중에 발생한 이벤트추척(선택)**\n",
    "- 모델, 에러 및 내용(발생시), 작업 상태, 사용된 데이터셋, 생성 및 완료 시간 등 확인 가능 (대시보드 - 파인튜닝 정보를 코드로 확인하는 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adae05-5181-4b9e-a310-b2001ff0c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id = job_id,\n",
    "                                    limit =5)       # 출력 개수 제한"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f87759-a055-409f-9ea4-4606af898254",
   "metadata": {},
   "source": [
    "##### **모든 파인튜닝 작업 현황 보기(선택)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0802ef7-9f8f-4ec4-9b0c-35375ff8a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.list()     # limit 매개변수를 통해 출력 개수를 제한할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453f374-6069-4077-b6cc-2061b9f2dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs.list에서 전체 작업 목록 id만 확인\n",
    "all_job_id = [job.id for job in client.fine_tuning.jobs.list()]\n",
    "all_job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf115b70-eac2-4148-8f14-d97411e18c34",
   "metadata": {},
   "source": [
    "##### **작업 취소 및 작업 삭제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6fe9df-1a80-47e0-8d0f-db5d2fda065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 작업 취소(오래걸리거나, 실수했을 때)\n",
    "# client.fine_tuning.jobs.cancel(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543e2c-a33d-4d43-89fa-82db47b80e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 작업 삭제\n",
    "# client.models.delete(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea00b0-74fb-4361-a403-f9835fb06e35",
   "metadata": {},
   "source": [
    "##### **파인튜닝 후 대화하는 법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e118d46-e716-40b8-bdd9-c15104fe6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model = model_id,\n",
    "    messages = [{\"role\" : \"user\", \"content\" : \"우리나라의 첫 대통령은 누구인가?\"}]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116fa2f-1b28-4450-8e19-3fea0e80ee84",
   "metadata": {},
   "source": [
    "## Fine-tuning 결과가 좋지 않다고 판단될 경우 대응\n",
    "**1) 데이터 부분**\n",
    "1) 데이터 수 추가\n",
    "    - 가장 효과가 확실한 방법\n",
    "2) 데이터의 균형과 다양성 고려\n",
    "    - 균형을 맞춰야 한다면 일반적으로 적은양의 고품질 데이터가 많은 양의 저품질 데이터보다 효과적\n",
    "3) 기존 데이터의 문제점 조사\n",
    "    - 원치않는 방식의 대화 데이터가 포함되어 있는지 확인(잘못된 패턴이 학습되었을 수 있음)\n",
    "    - 응답에 필요한 모든 정보가 포함되어 있는지 확인\n",
    "    - 여러 사람들이 함께 제작한 데이터라면 어느정도 일관성이 있는지 확인(패턴이 다 달라서 학습하기 힘들 수 있음)\n",
    "      \n",
    "**2) 모델 부분**\n",
    "1) 완료된 모델에 추가로 fine-tuning 진행\n",
    "    - 완료된 모델의 모델명으로 fine-tuning을 이어서 진행 가능\n",
    "2) 하이퍼파라미터 변경\n",
    "    - epochs, learning_rate를 변경 가능\n",
    "\n",
    "**3) 평가지표**\n",
    "1) mean_token_accuracy\n",
    "2) loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2b328-a9ea-4346-add5-47967221ee86",
   "metadata": {},
   "source": [
    "##### **체크포인트(중간저장) 모델 활용하기**\n",
    "- Fine-tunig 완료 시 체크포인트 모델을 활용할 수 있으며 체크포인트 모델은 학습이 최종 완료된 모델과 동일한 방식으로 사용 가능\n",
    "- 현재는 완료된 작업 총 `3개의 체크포인트 모델`들만 사용 가능함\n",
    "- 최종 모델의 성능이 애매하거나 수치적으로 과대적합이라고 판단된다면 이전 체크포인트 모델들을 활용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080a20a-c2f5-491e-88f8-23f85024fb48",
   "metadata": {},
   "source": [
    "**코드 없이 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3251929-40d4-43b4-b1c1-49c9be660561",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-Ft82dD32EH1jaOumUtXOFHEv/checkpoints \\\n",
    "  -H \"Authorization: Bearer $MY_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca1adf-c95b-4571-b13b-1c050c358e24",
   "metadata": {},
   "source": [
    "**코드로 확인(더 자세함)**\n",
    "- mean_token_accuracy가 높아지는지, loss가 낮아지는지 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bc88f-a0f0-4047-b3e6-e04a8e7e83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.list_events(\n",
    "    fine_tuning_job_id = \"ftjob-Ft82dD32EH1jaOumUtXOFHEv\",\n",
    ")\n",
    "\n",
    "# loss는 낮아지고 train_mean_token_accuracy는 낮아지는지 확인\n",
    "# model_dump_json : 객체를 json문자열로 변환하는 함수\n",
    "print(response.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdb6aa-1726-41a3-a2da-378652c87263",
   "metadata": {},
   "source": [
    "## 추가학습 및 검증 데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5044d-5572-40bc-bc24-fdc5b2a1b0cb",
   "metadata": {},
   "source": [
    "##### **추가 데이터 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d9e42-a26c-473d-b32d-6e8acd7f1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finetune_data/common_sense_train_add.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "print( \"샘플 수 :\", len(dataset))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93390cba-b572-4d3d-838f-caa6832f8039",
   "metadata": {},
   "source": [
    "##### **추가 학습 데이터 업로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c800740-9bc0-4373-8ae5-d0c0faa1343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_files_add = client.files.create(\n",
    "    file = open(\"finetune_data/common_sense_train_add.jsonl\", \"rb\"),  # rb를 하면 encoding이 필요 없음\n",
    "    purpose = \"fine-tune\"\n",
    ")\n",
    "fine_tune_files_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6c37d-c9ed-4e65-841e-cdcf073f84e0",
   "metadata": {},
   "source": [
    "##### **검증 데이터 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f5e92-e281-4c1c-86b1-5d9e63770b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finetune_data/common_sense_val.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "print( \"샘플 수 :\", len(dataset))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea8f85-dc5b-46cd-9a51-e133a3b01304",
   "metadata": {},
   "source": [
    "##### **검증 데이터 업로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07a9cf-fcba-45eb-90c5-3ca326cde019",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_files_val = client.files.create(\n",
    "    file = open(\"finetune_data/common_sense_val.jsonl\", \"rb\"),  # rb를 하면 encoding이 필요 없음\n",
    "    purpose = \"fine-tune\"\n",
    ")\n",
    "fine_tune_files_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a81c2-605f-49fa-8030-5d629e0115cb",
   "metadata": {},
   "source": [
    "##### **추가 Fine-tuning 및 검증 진행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccc6a7-a362-4223-a53d-a3e692f9a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_job_add = client.fine_tuning.jobs.create(\n",
    "    model = \"ft:gpt-4o-mini-2024-07-18:personal::B1pKdhoJ\", # 기존 학습된 모델\n",
    "    training_file = fine_tune_files_add.id,                 # 추가 학습 데이터 아이디\n",
    "    validation_file = fine_tune_files_val.id,               # 검증용 데이터 아이디\n",
    "    hyperparameters = {\"n_epochs\" : 5,\n",
    "                       \"learning_rate_multiplier\" : 0.8\n",
    "                      }\n",
    ")\n",
    "\n",
    "# learning_rate_multiplier(학습률)\n",
    "# GPT-3.5/4 계열 모델: 0.1 ~ 0.5\n",
    "# 데이터가 많고 Fine-Tuning 강도를 높이고 싶다면: 0.5 ~ 1.0\n",
    "# 데이터가 적거나 기존 성능을 유지하면서 미세 조정하고 싶다면: 0.05 ~ 0.2\n",
    "\n",
    "fine_tune_job_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99c668-051e-46fd-81ef-e11e32de4012",
   "metadata": {},
   "source": [
    "##### **학습 결과 epochs별로 확인, 체크포인트 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103af6e-d760-4b90-8a0f-8290e0a6d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.list_events(\n",
    "    fine_tuning_job_id = \"ftjob-x2NOix27Qk6THUxkrQjk2I09\",\n",
    ")\n",
    "print(response.model_dump_json(indent=4)) # 객체를 json문자열로 변환"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:study]",
   "language": "python",
   "name": "conda-env-study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
