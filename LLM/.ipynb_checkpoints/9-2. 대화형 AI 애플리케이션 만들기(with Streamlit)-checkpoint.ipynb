{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT APIì™€ Streamlitì„ í™œìš©í•˜ì—¬ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” ëŒ€í™”í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì–´ë³´ì~!\n",
    "- ì´ì „ ëŒ€í™”ë¥¼ ë©”ëª¨ë¦¬ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ í™œìš©í•´ë³´ì\n",
    "- ì´ë¥¼ ì ìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ê³  streamlitìœ¼ë¡œ êµ¬ë™ì‹œì¼œë³´ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (1.37.1)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.42.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\jae_4\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\jae_4\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jae_4\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jae_4\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jae_4\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jae_4\\anaconda3\\envs\\study\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jae_4\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.42.1-py2.py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 5.2/9.6 MB 29.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 27.0 MB/s eta 0:00:00\n",
      "Installing collected packages: streamlit\n",
      "  Attempting uninstall: streamlit\n",
      "    Found existing installation: streamlit 1.37.1\n",
      "    Uninstalling streamlit-1.37.1:\n",
      "      Successfully uninstalled streamlit-1.37.1\n",
      "Successfully installed streamlit-1.42.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-decouple\n",
      "  Downloading python_decouple-3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Downloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
      "Installing collected packages: python-decouple\n",
      "Successfully installed python-decouple-3.8\n"
     ]
    }
   ],
   "source": [
    "# APIí‚¤, DB ìê²©ì¦ëª… ë° í™˜ê²½ë³€ìˆ˜ì™€ ê°™ì€ êµ¬ì„± ì„¤ì •ì„ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•´ì£¼ëŠ” íŒ¨í‚¤ì§€\n",
    "!pip install python-decouple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì´ì „ ì‹¤ìŠµë“¤ì—ëŠ” ì—¬ëŸ¬ ì…€ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì„œ getpassë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ Streamlitì„ ë™ì‘ì‹œí‚¬ ë•ŒëŠ” í•˜ë‚˜ì˜ ì…€ì— ëª¨ë“  ì½”ë“œê°€ ë“¤ì–´ê°„ pyíŒŒì¼ë¡œ ë™ì‘ì‹œì¼œì•¼í•˜ê¸° ë•Œë¬¸ì— api-keyê°€ ë³´ì¼ ìˆ˜ ë°–ì— ì—†ìŒ\n",
    "- ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ Streamlitì—ì„œ ì§€ì›í•˜ëŠ” ë¹„ë°€ ê´€ë¦¬ ê¸°ëŠ¥(secrets)ì„ í™œìš©í•´ë³´ì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**%%writefile : í•´ë‹¹ ì…€ì„ pyíŒŒì¼ì²˜ëŸ¼ ì‚¬ìš©í•˜ëŠ” ì½”ë“œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting module/myChatApp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile module/myChatApp.py\n",
    "\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from openai import OpenAI\n",
    "\n",
    "#\n",
    "chat_model = ChatOpenAI(model_name='gpt-3.5-turbo',\n",
    "                        api_key = st.secrets[\"OPENAI_API_KEY\"],\n",
    "                        temperature = 0.5\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(input_variables = [\"chat_history\", \"question\"],\n",
    "                        template = \"\"\"You are a AI assistant.\n",
    "                                      You are currently haing a conversation with a human.\n",
    "                                      Answer the Question.\n",
    "                                      chat_history : {chat_history},\n",
    "                                      Human : {question},\n",
    "                                      AI assistant : \n",
    "                                      \"\"\"\n",
    "                       )\n",
    "\n",
    "# ì¼ë°˜ì ì¸ ì½”ë“œì—ì„œëŠ” memoryê°ì²´ë¥¼ ìƒì„±í•˜ë©´ ëŒ€í™” ë‚´ìš©ë“¤ì„ ìë™ìœ¼ë¡œ ê¸°ì–µí•˜ì§€ë§Œ \n",
    "# streamlitì—ì„œëŠ” ì›¹ì—ì„œ ìš”ì²­, ë‹µì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— ë”°ë¡œ ì§€ì •í•´ë‘ì§€ ì•Šìœ¼ë©´ ë‹¤ ì´ˆê¸°í™” ë¨\n",
    "\n",
    "# session_state : ë”•ì…”ë„ˆë¦¬ì™€ ìœ ì‚¬í•œ êµ¬ì¡°ë¡œ ëª¨ë“  ìë£Œí˜• ë° ê°ì²´ë¥¼ ì§€ì •í•  ìˆ˜ ìˆê³  []ì™¸ì— .ìœ¼ë¡œë„ keyì— ì ‘ê·¼ ê°€ëŠ¥\n",
    "#                  ì•±ì„ ì¬ì‹¤í–‰í•´ë„ ì‚¬ìš©ì ì…ë ¥ì´ë‚˜ ê³„ì‚°ê²°ê³¼ ë“± ë³€ìˆ˜ì˜ ìƒíƒœë¥¼ ì§€ì†ì ìœ¼ë¡œ ê´€ë¦¬í•´ì•¼ í•  ë•Œ ì‚¬ìš©í•¨\n",
    "\n",
    "\n",
    "# ì²˜ìŒë¶€í„° ì§€ì •í•˜ì§€ ì•Šê³  not inì„ ì“°ëŠ” ì´ìœ ëŠ” ì½”ë“œ ì¬ì‹¤í–‰ ì‹œ ì§€ì •ëœ ê°’ì´ ì´ˆê¸°í™” ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•¨\n",
    "if \"pre_memory\" not in st.session_state:\n",
    "    st.session_state.pre_memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "                                                           return_messages=True\n",
    "                                                          )\n",
    "\n",
    "llm_chain = LLMChain(llm=chat_model,\n",
    "                     prompt=my_prompt,\n",
    "                     memory=st.session_state.pre_memory # CBMemoryê°ì²´ê°€ ì…ë ¥ ë¨\n",
    "                    )\n",
    "\n",
    "# LLMì— ìš”ì²­í•˜ê³  ì‘ë‹µë°›ì„ ìˆ˜ ìˆëŠ” chatí˜•íƒœë¡œ messagesë¥¼ ê´€ë¦¬\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state_messages = [\n",
    "        {\"role\" : \"assistant\", \"content\" : \"ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” AI Assistantì…ë‹ˆë‹¤.\"}\n",
    "    ]\n",
    "\n",
    "# ------------------------ ì›¹í‘œì‹œ ë¶€ë¶„ -----------------------------------\n",
    "st.title(\"ë‚˜ì˜ ì‘ê³  ì†Œì¤‘í•œ GPT ì±—ë´‡ğŸ˜Š\")\n",
    "\n",
    "# ë°˜ë³µë¬¸ìœ¼ë¡œ session_state.messagesì— ìˆëŠ” ëª¨ë“  ëŒ€í™” ê¸°ë¡ì— ì ‘ê·¼\n",
    "for message in st.session_state.messages:\n",
    "    # chat_message : ë©”ì„¸ì§€ì˜ ë°œì‹ ì role(assistant, user)ì— ë”°ë¼ UIë¥¼ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥\n",
    "    #                assistant, userëŠ” ë””í´íŠ¸ë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©° ë‹¤ë¥¸ roleì„ ì¶”ê°€í•˜ë ¤ë©´ html ì½”ë“œ ì‘ì„±ì´ í•„ìš”\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# chat_input : ì±„íŒ…ë©”ì„¸ì§€ ì…ë ¥ UIê°€ ìƒì„±ë˜ë©° ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜\n",
    "user_prompt = st.chat_input()\n",
    "\n",
    "# ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•œë‹¤ë©´!\n",
    "if user_prompt is not None:\n",
    "    st.session_state.message.append({\"role\" : \"user\", \"content\" : user_prompt})\n",
    "    with st.chat_message(\"user\"):  # userí˜•íƒœë¡œ ë©”ì„¸ì§€ ì°½ UI ì¶œë ¥\n",
    "        st.write(user_prompt)      # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ ì¶œë ¥\n",
    "\n",
    "# ë§ˆì§€ë§‰ ë©”ì„¸ì§€ì˜ roleì´ assistantê°€ ì•„ë‹ˆë¼ë©´ ìƒˆë¡œìš´ ë‹µë³€ì„ ìƒì„±í•˜ê³  session_stateì— ì¶”ê°€\n",
    "# (assistantê°€ ë³¸ì¸ì˜ ì‘ë‹µì—ë„ ê³„ì† ëŒ€ë‹µí•˜ëŠ” ìë¬¸ìë‹µì„ ë°©ì§€í•˜ê¸° ìœ„í•¨)\n",
    "if st.session_state.messages[-1][\"role\"] != \"assistant\" :\n",
    "    # assistant ë©”ì„¸ì§€ UI ìƒì„±\n",
    "    with st.chat_message(\"assistant\") :\n",
    "        # \n",
    "        with st.spinner(\"Loading..\") :\n",
    "            try :\n",
    "                ai_response = llm_chain.predict(question=user_prompt)\n",
    "                st.write(ai_response)\n",
    "                # ëª¨ë¸ì˜ ì‘ë‹µë„ ì„¸ì…˜ì˜ messagesì— ì¶”ê°€í•˜ì—¬ ê´€ë¦¬\n",
    "                st.session_state.messages.append({\"role\" : \"assistant\", \"content\" : ai_response})\n",
    "            except Exception as e:\n",
    "                st.error(f\"LLM ì—ëŸ¬ ë°œìƒ : {e}\")\n",
    "\n",
    "                 \n",
    "#------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:study]",
   "language": "python",
   "name": "conda-env-study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
